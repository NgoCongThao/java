import os
from dotenv import load_dotenv
from langchain_community.document_loaders import DirectoryLoader, TextLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter, Language
from langchain_ollama import OllamaEmbeddings
from langchain_chroma import Chroma

# Load biáº¿n mÃ´i trÆ°á»ng
load_dotenv()

ROOT_DIR = os.getenv("PROJECT_ROOT_PATH")
DB_DIR = os.getenv("VECTOR_DB_PATH")
EMBED_MODEL = os.getenv("EMBEDDING_MODEL")

def scan_and_ingest():
    print(f"ğŸ”„ Äang quÃ©t file 'data*.js' tá»«: {os.path.abspath(ROOT_DIR)}")

    # 1. QuÃ©t file (Loáº¡i bá» folder rÃ¡c)
    loader = DirectoryLoader(
        path=ROOT_DIR,
        glob="**/data*.js", 
        loader_cls=TextLoader,
        exclude=["**/node_modules/**", "**/.git/**", "**/backend/**", "**/frontend/**"],
        show_progress=True
    )

    try:
        docs = loader.load()
        if not docs:
            print("âš ï¸ KhÃ´ng tÃ¬m tháº¥y file nÃ o! Kiá»ƒm tra láº¡i Ä‘Æ°á»ng dáº«n.")
            return
        print(f"âœ… TÃ¬m tháº¥y {len(docs)} file.")
    except Exception as e:
        print(f"âŒ Lá»—i Ä‘á»c file: {e}")
        return

    # 2. Chia nhá» code JS
    text_splitter = RecursiveCharacterTextSplitter.from_language(
        language=Language.JS, chunk_size=1000, chunk_overlap=100
    )
    chunks = text_splitter.split_documents(docs)
    
    # 3. Embed & LÆ°u DB
    print("ğŸ’¾ Äang lÆ°u vÃ o Vector DB...")
    embedding = OllamaEmbeddings(model=EMBED_MODEL)
    Chroma.from_documents(documents=chunks, embedding=embedding, persist_directory=DB_DIR)
    print("ğŸ‰ Xong! Dá»¯ liá»‡u Ä‘Ã£ sáºµn sÃ ng.")

if __name__ == "__main__":
    scan_and_ingest()